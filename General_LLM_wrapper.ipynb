{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\33766\\Documents\\Travail\\TU Delft\\Q3\\Machine Learning Bayesian\\Assignment2ML\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ======================== IMPORTS ============================\n",
    "import os, json, faiss, numpy as np, pytesseract, PyPDF2, threading, queue, pyttsx3\n",
    "import speech_recognition as sr\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "from duckduckgo_search import DDGS\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Store dynamic assignment per prompt\n",
    "current_arena_assignment = {}\n",
    "\n",
    "# ======================== CHATBOT CLASS ============================\n",
    "class ChatBot:\n",
    "    def __init__(self, model=\"llama3.2:3b\"): # Can use llama3.2:3b or llama3.2:1b  or llama3-1b-spamgen \n",
    "        self.model = model\n",
    "        self.system_prompt = \"Answer by clear small useful answers. Short responses.\"\n",
    "        self.global_settings = {\"max_tokens\": 50, \"temperature\": 0.7}\n",
    "        self.chat_history = [{'role': 'system', 'content': self.system_prompt}]\n",
    "\n",
    "        self.rag_embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.rag_chunks, self.rag_index = [], None\n",
    "\n",
    "        self.voice_enabled = False\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.mic = sr.Microphone()\n",
    "        self.tts_queue = queue.Queue()\n",
    "        threading.Thread(target=self._tts_loop, daemon=True).start()\n",
    "\n",
    "    # ----------- Text-to-Speech ------------\n",
    "    def _tts_loop(self):\n",
    "        while True:\n",
    "            text = self.tts_queue.get()\n",
    "            if text is None:\n",
    "                break\n",
    "            try:\n",
    "                engine = pyttsx3.init()  # move inside the loop\n",
    "                engine.setProperty('voice', 'HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Speech\\\\Voices\\\\Tokens\\\\TTS_MS_EN-US_ZIRA_11.0')\n",
    "                engine.say(text)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "            except Exception as e:\n",
    "                print(f\"TTS error: {e}\")\n",
    "\n",
    "\n",
    "    def speak(self, text):\n",
    "        if self.voice_enabled:\n",
    "            self.tts_queue.put(text)\n",
    "\n",
    "    def stop_audio(self):\n",
    "        self.tts_queue.put(None)\n",
    "        self.voice_enabled = False\n",
    "\n",
    "    # ----------- Document Loading ------------\n",
    "    def load_document(self, file_objs):\n",
    "        chunks, summaries = [], []\n",
    "        for f in file_objs:\n",
    "            try:\n",
    "                reader = PyPDF2.PdfReader(f.name)\n",
    "                texts = [p.extract_text().strip() for p in reader.pages if p.extract_text()]\n",
    "                chunks.extend(texts)\n",
    "                summaries.append(f\"**{os.path.basename(f.name)}**: \" + \"\\n\".join(texts[:2]))\n",
    "            except Exception as e:\n",
    "                summaries.append(f\"Error reading {f.name}: {e}\")\n",
    "        if chunks:\n",
    "            self.rag_chunks = chunks\n",
    "            embeddings = self.rag_embedder.encode(chunks)\n",
    "            self.rag_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "            self.rag_index.add(np.array(embeddings))\n",
    "            return \"\\n\\n\".join(summaries)\n",
    "        return \"No valid PDF content loaded.\"\n",
    "    # ----------- OCR Image Loading ------------\n",
    "\n",
    "    def load_image(self, file_obj):\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(Image.open(file_obj.name)).strip()\n",
    "            if text:\n",
    "                self.rag_chunks = [text]\n",
    "                embeddings = self.rag_embedder.encode(self.rag_chunks)\n",
    "                self.rag_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "                self.rag_index.add(np.array(embeddings))\n",
    "                return f\"Extracted text:\\n{text[:500]}...\"\n",
    "            return \"No text found.\"\n",
    "        except Exception as e:\n",
    "            return f\"Image error: {e}\"\n",
    "\n",
    "    # ----------- Context Retrieval ------------\n",
    "    def retrieve_context(self, query, top_k=2):\n",
    "        if not self.rag_index: return \"\"\n",
    "        query_emb = self.rag_embedder.encode([query])\n",
    "        D, I = self.rag_index.search(np.array(query_emb), top_k)\n",
    "        return \"\\n\".join(self.rag_chunks[i] for i in I[0])\n",
    "\n",
    "    # ----------- Internet Search ------------\n",
    "    def internet_search(self, query, max_results=3):\n",
    "        results = []\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                for r in ddgs.text(query, max_results=max_results):\n",
    "                    results.append(f\"{r.get('title', '')}: {r.get('body', '')} ({r.get('href', '')})\")\n",
    "        except Exception as e:\n",
    "            results.append(f\"Search error: {e}\")\n",
    "        return \"\\n\".join(results)\n",
    "\n",
    "    # ----------- Chat Functions ------------\n",
    "    def chat(self, user_input, search_enabled=False):\n",
    "        search_context = self.internet_search(user_input) if search_enabled else \"\"\n",
    "        context = \"\"\n",
    "        if search_enabled:\n",
    "            context += \"Relevant internet search results:\\n\" + self.internet_search(user_input) + \"\\n\"\n",
    "        rag_context = self.retrieve_context(user_input)\n",
    "        if rag_context:\n",
    "            context += \"RAG user document:\\n\" + rag_context + \"\\n\"\n",
    "        prompt = f\"Context:\\n{context}\\nQuestion: {user_input}\\nAnswer:\" if context else user_input\n",
    "\n",
    "        self.chat_history.append({'role': 'user', 'content': prompt})\n",
    "        response = ollama.chat(model=self.model, messages=self.chat_history, options=self.global_settings)\n",
    "        reply = response['message']['content'].strip()\n",
    "        self.chat_history.append({'role': 'assistant', 'content': reply})\n",
    "        self.speak(reply)\n",
    "        return reply, search_context\n",
    "    # ----------- Voice Input ------------\n",
    "    def listen(self):\n",
    "        with self.mic as source:\n",
    "            audio = self.recognizer.listen(source)\n",
    "        try:\n",
    "            return self.recognizer.recognize_google(audio)\n",
    "        except:\n",
    "            return \"Voice recognition error.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33766\\AppData\\Local\\Temp\\ipykernel_30016\\2178421024.py:40: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat_display = gr.Chatbot(label=\"Chat History\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================== GRADIO INTERFACE (NO ARENA MODE) ============================\n",
    "\n",
    "bot = ChatBot()  # Initialize chatbot instance\n",
    "\n",
    "# ---------------- Helper Functions ----------------\n",
    "\n",
    "def handle_upload(files):\n",
    "    if not files:\n",
    "        return \"No file uploaded.\"\n",
    "    file = files[0]\n",
    "    return bot.load_document(files) if file.name.lower().endswith(\"pdf\") else bot.load_image(file)\n",
    "\n",
    "def toggle_voice_output():\n",
    "    bot.voice_enabled = not bot.voice_enabled\n",
    "    return \"ðŸ”Š\" if bot.voice_enabled else \"ðŸ”‡\"\n",
    "\n",
    "def clear_chat():\n",
    "    bot.chat_history = [{'role': 'system', 'content': bot.system_prompt}]\n",
    "    return []\n",
    "\n",
    "def toggle_search(search_state):\n",
    "    new_state = not search_state\n",
    "    return new_state, f\"Search: {'ON' if new_state else 'OFF'}\"\n",
    "\n",
    "# ---------------- Chat Handler ----------------\n",
    "def handle_main(msg, history, search):\n",
    "    reply, sctx = bot.chat(msg, search_enabled=search)\n",
    "    history.append((msg, reply))\n",
    "    return history, \"\", sctx\n",
    "\n",
    "# ---------------- Gradio Interface ----------------\n",
    "\n",
    "with gr.Blocks(css=\".gradio-container {width:100%; max-width:none;}\") as demo:\n",
    "    gr.Markdown(\"# Delftbot ðŸ”¥\")\n",
    "\n",
    "    # States to persist toggle buttons\n",
    "    search_state = gr.State(False)\n",
    "\n",
    "    # Chat display and input textbox\n",
    "    chat_display = gr.Chatbot(label=\"Chat History\")\n",
    "    user_input = gr.Textbox(label=\"Your Message\", placeholder=\"Type here...\")\n",
    "\n",
    "    # Control buttons\n",
    "    with gr.Row():\n",
    "        mic_btn = gr.Button(\"ðŸŽ¤\")\n",
    "        speaker_btn = gr.Button(\"ðŸ”‡\")\n",
    "        search_btn = gr.Button(\"Search: OFF\")\n",
    "        clear_btn = gr.Button(\"ðŸ§¹ Clear Chat\")\n",
    "\n",
    "    # File upload and summaries\n",
    "    file_upload = gr.File(label=\"Upload PDF/Image\", file_count=\"multiple\")\n",
    "    file_summary = gr.Textbox(label=\"File Summary\", interactive=False)\n",
    "\n",
    "    # ---------------- Event Bindings ----------------\n",
    "\n",
    "    # Submit text input\n",
    "    user_input.submit(fn=handle_main,\n",
    "                      inputs=[user_input, chat_display, search_state],\n",
    "                      outputs=[chat_display, user_input, file_summary])\n",
    "\n",
    "    # Submit via mic input (speech-to-text)\n",
    "    mic_btn.click(fn=lambda h, s: handle_main(bot.listen(), h, s),\n",
    "                  inputs=[chat_display, search_state],\n",
    "                  outputs=[chat_display, user_input, file_summary])\n",
    "\n",
    "    # Toggle TTS audio\n",
    "    speaker_btn.click(fn=toggle_voice_output, outputs=speaker_btn)\n",
    "\n",
    "    # Toggle search mode\n",
    "    search_btn.click(fn=toggle_search,\n",
    "                     inputs=[search_state],\n",
    "                     outputs=[search_state, search_btn])\n",
    "\n",
    "    # Clear chat\n",
    "    clear_btn.click(fn=clear_chat, outputs=chat_display)\n",
    "\n",
    "    # Handle file upload (PDF/Image)\n",
    "    file_upload.change(fn=handle_upload, inputs=file_upload, outputs=file_summary)\n",
    "\n",
    "    # Enable request queuing and launch interface\n",
    "    demo.queue()\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
